{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f5e269a-323c-48a7-a4d9-35c5d294d0b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-langchain langchain databricks-sdk mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65d8ae1f-f249-4d0d-9ffc-9bb9bb56ab0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Tools\n",
    "\n",
    "We are going to create couple of tools for the purpose of conversation. \n",
    "\n",
    "1. SQL Tool : Extract customer information (based on customer credentials)\n",
    "2. SQL Tool :  Extract customer transaction based on customer ID\n",
    "3. SQL Tool : Extract customer portfolio based on customer ID\n",
    "4. SQL Tool : Extract fraud alert based on transaction ID\n",
    "5. Vector Search Retriver tool : VS search for advisory notes , fraud guidelines , policy investment guidelines\n",
    "6. Process Fraud Suspension \n",
    "7. Appointment Scheduler \n",
    "8. Genie Agent Tool (Optional with structured data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0597573-09f0-43f3-bf4d-e32b3a0190ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Define the catalog name for each user \n",
    "user_email = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get() \n",
    "email = str(user_email).split('@')\n",
    "catalog = email[0].replace('.','')\n",
    "\n",
    "schema = \"agent_workshop\"\n",
    "\n",
    "\n",
    "func_name_cust_details  = f\"{catalog}.{schema}.extract_customer_details\"\n",
    "func_name_portfolio_details  = f\"{catalog}.{schema}.extract_portfolio_details\"\n",
    "func_name_customer_transactions = f\"{catalog}.{schema}.extract_customer_transactions\"\n",
    "func_name_fraud_analysis = f\"{catalog}.{schema}.fraud_analysis\"\n",
    "func_name_customer_fraud = f\"{catalog}.{schema}.extract_customer_fraud\"\n",
    "func_name_transaction_details = f\"{catalog}.{schema}.extract_transaction_details\"\n",
    "func_name_rebalancing = f\"{catalog}.{schema}.simulate_rebalance_and_compare\"\n",
    "func_name_unstructured_vs_tool = f\"{catalog}.{schema}.internal_knowledge_search\"\n",
    "\n",
    "transaction_table = f\"{catalog}.{schema}.transactions\"\n",
    "customer_table = f\"{catalog}.{schema}.customers\"\n",
    "portfolio_table = f\"{catalog}.{schema}.portfolio\"\n",
    "fraud_table = f\"{catalog}.{schema}.fraud\"\n",
    "vs_index_name = f\"{catalog}.{schema}.guidance_gold_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70ff57b9-d841-43ac-a6d0-f9b0db2d34f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Extract Customer Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5180d64b-8be5-4637-b336-95c78716d58b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP FUNCTION IF EXISTS {func_name_cust_details}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {func_name_cust_details} (\n",
    "  customer_first_name STRING ,\n",
    "  customer_last_name STRING ,\n",
    "  post_code STRING\n",
    ")\n",
    "returns table (customer_id STRING,\n",
    "               Email STRING\n",
    "               )\n",
    " COMMENT \"This functions extracts customer ID and Email based on customer first , last name and PostCode\" \n",
    " RETURN\n",
    "  SELECT customer_id, Email FROM {customer_table}\n",
    "  where FirstName = customer_first_name \n",
    "  and LastName = customer_last_name\n",
    "  and PostalCode = post_code\n",
    "  \"\"\"\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f677fdc3-de88-4d90-ab59-285a8ca6b4d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"select * from {func_name_cust_details}('Danielle','Johnson','2461')\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dff201b4-6400-4539-b1fb-09d7bc52b55c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Extract Portfolio Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9178b423-1e8a-456b-bb1d-10c7cab85da4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP FUNCTION IF EXISTS {func_name_portfolio_details}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {func_name_portfolio_details} (\n",
    "  cust_id STRING \n",
    ")\n",
    "returns table (\n",
    "          customer_id STRING,\n",
    "          stock_name STRING,\n",
    "          quantity INTEGER,\n",
    "          current_value DECIMAL, \n",
    "          gain_loss_percentage DECIMAL\n",
    "               )\n",
    " COMMENT \"This functions extracts portfolio details based on customer ID\" \n",
    " RETURN\n",
    "  SELECT * FROM {portfolio_table}\n",
    "  where customer_id = cust_id\n",
    "  \"\"\"\n",
    "spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd8acd3-189c-4d5e-a893-f8f5a8cf8e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"select * from {func_name_portfolio_details}('CUST001')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf373151-e48b-44a8-aa55-273e26e90e86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"ALTER TABLE ananyaroy.finOps.customers ADD COLUMNS (`status` STRING)\")\n",
    "# spark.sql(\"UPDATE ananyaroy.finOps.customers SET `status` = 'active' WHERE `status` IS NULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2a069da-dcae-4c08-a778-f91e519262a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Extract transaction details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e68d29-080c-4d4e-bbef-6e4671562606",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP FUNCTION IF EXISTS {func_name_transaction_details}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {func_name_transaction_details} (\n",
    "  cust_id STRING   \n",
    ")\n",
    "RETURNS TABLE (\n",
    "          transaction_id STRING,\n",
    "          customer_id STRING,\n",
    "          amount DECIMAL,\n",
    "          date DATE, \n",
    "          location STRING\n",
    "               )\n",
    " COMMENT \"This functions extracts customer transaction details based on customer ID\" \n",
    " RETURN\n",
    "  SELECT * FROM {transaction_table}\n",
    "  where customer_id = cust_id\n",
    "  \"\"\"\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "098ea21e-a8ce-4354-9ff5-e20178f6e03a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"select * from {func_name_transaction_details}('CUST001')\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "473cc8eb-75ae-4310-8155-0a21488dc196",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Portoflio Rebalancing Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5cefe32-717c-48f8-b47f-ae112c7ad499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP FUNCTION IF EXISTS {func_name_rebalancing}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "          CREATE OR REPLACE FUNCTION {func_name_rebalancing}(\n",
    "          portfolio_list STRING COMMENT 'Customer Portfolio List',\n",
    "          customer_id STRING COMMENT 'Customer ID',\n",
    "          from_stock STRING COMMENT 'Stock symbol to reduce allocation from',\n",
    "          to_stock STRING COMMENT 'Stock symbol to increase allocation to',\n",
    "          percentage DOUBLE COMMENT 'Percentage of the from_stock value to reallocate to to_stock'\n",
    "        )\n",
    "        RETURNS DOUBLE\n",
    "        LANGUAGE PYTHON\n",
    "        DETERMINISTIC\n",
    "        COMMENT \"Simulates rebalancing of a customers stock portfolio and compares projected values before and after.\n",
    "        Args:\n",
    "            portfolio_list (str): a string list of dictionaries containing the customer\\'s portfolio.\n",
    "            customer_id (str): Unique identifier for the customer whose portfolio will be rebalanced.\n",
    "            from_stock (str): The stock symbol to reduce allocation from.\n",
    "            to_stock (str): The stock symbol to increase allocation to.\n",
    "            percentage (float): Percentage of the `from_stock` value to reallocate to `to_stock`.\n",
    "\n",
    "        Returns:\n",
    "            difference (float): The difference in forecasted portfolio value after rebalancing. Positive indicates gain.\n",
    "\n",
    "        Steps:\n",
    "            1. Fetch the customer\\'s portfolio.\n",
    "            2. Forecast portfolio value based on current value and gain/loss %.\n",
    "            3. Identify `from_stock` and `to_stock`.\n",
    "            4. Reallocate the specified percentage.\n",
    "            5. Forecast updated portfolio.\n",
    "            6. Return difference in projected values.\"\n",
    "        AS \n",
    "        $$\n",
    "          import pandas as pd \n",
    "          import ast\n",
    "\n",
    "          customer_portfolio = ast.literal_eval(portfolio_list)\n",
    "          columns = ['customer_id', 'stock_name', 'quantity', 'current_value', 'gain_loss_percentage']\n",
    "\n",
    "          customer_portfolio = pd.DataFrame(customer_portfolio, columns=columns)\n",
    "\n",
    "          original_df = customer_portfolio.copy()\n",
    "          original_df['forecasted_value'] = original_df['current_value'] * (1 + original_df['gain_loss_percentage'] / 100)\n",
    "          orig_total = original_df['forecasted_value'].sum()\n",
    "\n",
    "          source_portfolio = customer_portfolio[customer_portfolio['stock_name'] == from_stock]\n",
    "          target_portfolio = customer_portfolio[customer_portfolio['stock_name'] == to_stock]\n",
    "\n",
    "          if source_portfolio.empty or target_portfolio.empty:\n",
    "            raise ValueError(\"Stock names provided are not valid for this customer.\")\n",
    "\n",
    "          from_value = source_portfolio['current_value'].values[0]\n",
    "          to_value = target_portfolio['current_value'].values[0]\n",
    "          reallocation_value = from_value * (percentage / 100)\n",
    "\n",
    "          customer_portfolio.loc[customer_portfolio['stock_name'] == from_stock, 'current_value'] -= reallocation_value\n",
    "          customer_portfolio.loc[customer_portfolio['stock_name'] == to_stock, 'current_value'] += reallocation_value\n",
    "\n",
    "          rebalanced_df = customer_portfolio.copy()\n",
    "          rebalanced_df['forecasted_value'] = rebalanced_df['current_value'] * (1 + rebalanced_df['gain_loss_percentage'] / 100)\n",
    "          reb_total = rebalanced_df['forecasted_value'].sum()\n",
    "          difference = reb_total - orig_total\n",
    "\n",
    "          return difference\n",
    "        $$\n",
    "\"\"\"\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7054c1de-3aee-4fd3-9cf1-823eb1327c84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "\n",
    "client = DatabricksFunctionClient()\n",
    "customer_id = 'CUST001'\n",
    "query = f\"select * from {portfolio_table}  where customer_id = '{customer_id}'\"\n",
    "customer_portfolio = spark.sql(query)\n",
    "customer_portfolio = customer_portfolio.collect()\n",
    "customer_portfolio_str = str([row.asDict() for row in customer_portfolio])\n",
    "customer_portfolio_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "663160dc-eebc-42b9-a865-17864a28fa7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = client.execute_function(\n",
    "    function_name=func_name_rebalancing,\n",
    "    parameters={\n",
    "        \"percentage\": 5.0,\n",
    "        \"customer_id\": \"CUST001\",\n",
    "        \"portfolio_list\": customer_portfolio_str,\n",
    "        \"to_stock\": \"Netflix\",\n",
    "        \"from_stock\": \"Amazon\"\n",
    "      }\n",
    "  )\n",
    "result.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b99d9c5c-c6c2-472c-a7f9-7e2083d9d733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Fraud Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b821c159-56fd-472a-9091-c2c41d00ce15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP FUNCTION IF EXISTS {func_name_fraud_analysis}\")\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {func_name_fraud_analysis} (\n",
    "  cust_id STRING \n",
    ")\n",
    "returns table (\n",
    "        transaction_id STRING,\n",
    "        customer_id STRING,\n",
    "        alert_description STRING,\n",
    "        severity_level STRING,\n",
    "        amount DECIMAL,\n",
    "        date DATE, \n",
    "        location STRING,\n",
    "        analyst_notes STRING\n",
    "               )\n",
    " COMMENT \"This functions extracts transaction and fraud details from respective tables to assess for fraud in customers account. Use this function when customers asks about suspiscious activity in their email and want to understand if any fraud has happened\" \n",
    " RETURN\n",
    "  SELECT \n",
    "  frd.transaction_id,\n",
    "  trxn.customer_id ,\n",
    "  frd.alert_description,\n",
    "  frd.severity_level, \n",
    "  trxn.amount,\n",
    "  trxn.date, \n",
    "  trxn.location ,\n",
    "  frd.analyst_notes\n",
    "  FROM \n",
    "    {transaction_table} trxn \n",
    "  inner join \n",
    "      {fraud_table} frd \n",
    "  on trxn.transaction_id = frd.transaction_id\n",
    "  and trxn.customer_id = cust_id\n",
    "  \"\"\"\n",
    "spark.sql(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc9d8dc7-bd2c-4457-bdc0-2ab488221107",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"select * from {func_name_fraud_analysis}('CUST001')\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61c7c801-b9aa-4714-adaa-256b1b869af2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Vectorsearch Retriever Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa8bf813-ecbe-4c97-9eae-d1875c21bdf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {func_name_unstructured_vs_tool} (\n",
    "  -- The agent uses this comment to determine how to generate the query string parameter.\n",
    "  query STRING\n",
    "  COMMENT 'The query string for searching any internal knowledge on guidance on different matter.'\n",
    ") RETURNS TABLE\n",
    "-- The agent uses this comment to determine when to call this tool. It describes the types of documents and information contained within the index.\n",
    "COMMENT 'Executes a search on internal knowledge for guidance on portfolio and fraud.Guidance can be on matters like advisory note ,rebalancing,investment portfolio , fraud identification and policies , investment suggestions etc.'\n",
    " RETURN\n",
    "SELECT\n",
    "  file_content as page_content,\n",
    "  map('doc_uri', file_name) as metadata\n",
    "FROM\n",
    "  vector_search(\n",
    "    index => '{vs_index_name}', -- Define the vector search index name\n",
    "    query => query,\n",
    "    num_results => 3\n",
    "  )\"\"\"\n",
    "spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74ca31f-304b-4bc3-ae16-40271f520af2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "from unitycatalog.ai.langchain.toolkit import UCFunctionToolkit\n",
    "from unitycatalog.ai.core.databricks import DatabricksFunctionClient\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "# Create a toolkit with the UC function\n",
    "client = DatabricksFunctionClient()\n",
    "\n",
    "sample_quesetion = \"What is the company guideline for any suspiscious activity on transactions?\"\n",
    "\n",
    "# manually defining the func name as I want to test only this functionality\n",
    "toolkit = UCFunctionToolkit(\n",
    "    function_names=[func_name_unstructured_vs_tool],\n",
    "        client=client \n",
    ")\n",
    "tools = toolkit.tools\n",
    "\n",
    "LLM_ENDPOINT_NAME = \"databricks-meta-llama-3-3-70b-instruct\"\n",
    "model = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# Define the prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use tools for computations if applicable.\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "# Create a simple LangChain agent agent with our newly defined vs tool \n",
    "agent = create_tool_calling_agent(model, toolkit.tools, prompt)\n",
    "\n",
    "# Create an agent executor via LangChain, adding our defined tools from the UCFunctionToolkit instance\n",
    "agent_executor = AgentExecutor(agent=agent, tools=toolkit.tools, verbose=True)\n",
    "\n",
    "# Run the agent with an input\n",
    "agent_executor.invoke({\"input\": sample_quesetion})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4e676b7-9e59-4cbf-a16c-0cfb5990dda3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1379979344778598,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "02-create-tools",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
