{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00b9b25d-0c60-4d35-b4bb-e36c5d4851cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker databricks-langchain langchain databricks-sdk mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ba80da2-3d83-45e4-9308-029ff5019e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Financial Wealth Intelligence Assistant\n",
    "\n",
    "Through this workshop, we are building a **conversational financial Weath Intelligence Assisst** that assists customers and enterprises with understanding, optimising, and protecting their investment portfolios.\n",
    "\n",
    "The assistant is capable of:\n",
    "- ðŸ“Š Analysing a customer's portfolio performance\n",
    "- ðŸ“ˆ Suggesting improvements and rebalancing strategies\n",
    "- ðŸš¨ Identifying anomalies or fraud-related risks\n",
    "- ðŸ§  Answering questions using internal financial guidance\n",
    "- ðŸ”” Triggering alerts or next steps when risks are detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b068e8eb-ebec-4a42-83be-81c1e2ab88ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Generate synthetic data for this use case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d8c46f-3e87-4bd2-b103-241da0a66cfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import ChatMessage, ChatMessageRole\n",
    "\n",
    "def generate_synth_content(stock,system_prompt,user_prompt):\n",
    "\n",
    "  w = WorkspaceClient()\n",
    "  response = w.serving_endpoints.query(\n",
    "      name=\"databricks-claude-3-7-sonnet\",\n",
    "      messages=[\n",
    "          ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "          ChatMessage(role=ChatMessageRole.USER, content=user_prompt),\n",
    "      ],\n",
    "  )\n",
    "  notes = response.choices[0].message.content\n",
    "\n",
    "  return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d67a20-fea5-4f78-9ca0-c863521f8847",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Define the catalog name for each user \n",
    "workspace_url = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\n",
    "digits = ''.join(filter(str.isdigit, workspace_url))\n",
    "catalog = 'catalog_' + digits\n",
    "\n",
    "#Define the schema name for the workshop\n",
    "schema=\"agent_workshop\"\n",
    "full_schema_name = f\"{catalog}.{schema}\"\n",
    "\n",
    "# spark.sql(f\"create CATALOG if not exists labuser\")\n",
    "spark.sql(f\"create SCHEMA if not exists {full_schema_name}\")\n",
    "spark.sql(f\"DESCRIBE  SCHEMA {full_schema_name}\")\n",
    "\n",
    "#Define necessary tables\n",
    "customer_table = f\"{catalog}.{schema}.customers\"\n",
    "portfolio_table = f\"{catalog}.{schema}.portfolio\"\n",
    "transaction_table = f\"{catalog}.{schema}.transactions\"\n",
    "fraud_table = f\"{catalog}.{schema}.fraud\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "197ee2b4-9c9b-4e4e-ae9f-c2009947eeb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Generate structured synthetic data\n",
    "\n",
    "Let's generate synthetic data for a financial agent demo, including four core tables:\n",
    "\n",
    "- **`customers`**: 300 fake customers with personal and contact info\n",
    "- **`portfolio`**: Simulated stock holdings per customer across 7 majot tech stocks\n",
    "- **`transactions`**: 1,000 fake transactions with amount, date, and location\n",
    "- **`fraud`**: Around 200 flagged transactions with alert descriptions and analyst notes\n",
    "\n",
    "Data is generated using `Faker`, `random`, and `numpy`, and saved into Delta tables for downstream querying and agent use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111a79f5-7fa7-45d2-a858-61c59f5afe46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = Faker('en_AU')\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- 1. Generate Customers Table ---\n",
    "num_customers = 300\n",
    "\n",
    "customers = []\n",
    "for i in range(1, num_customers + 1):\n",
    "    customers.append({\n",
    "        \"customer_id\": 'CUST00'+ str(i),\n",
    "        \"FirstName\": fake.first_name(),\n",
    "        \"LastName\": fake.last_name(),\n",
    "        \"Email\": fake.email(),\n",
    "        \"PhoneNumber\": fake.phone_number(),\n",
    "        \"Address\": fake.address(),\n",
    "        \"City\": fake.city(),\n",
    "        \"State\": fake.state(),\n",
    "        \"PostalCode\": fake.postcode(),\n",
    "        \"Country\": fake.country(),\n",
    "        \"DateOfBirth\": fake.date_of_birth(minimum_age=18, maximum_age=80),\n",
    "        \"RegistrationDate\": fake.date_this_decade()\n",
    "    })\n",
    "customers_df = pd.DataFrame(customers)\n",
    "\n",
    "#store the customer table into delta\n",
    "spark.createDataFrame(customers_df).write.mode(\"overwrite\").saveAsTable(customer_table)\n",
    "display(customers_df.head(5))\n",
    "\n",
    "\n",
    "# --- 2. Generate Portfolio Table ---\n",
    "portfolio = []\n",
    "stocks = [\"Apple\", \"Tesla\", \"Amazon\", \"Microsoft\", \"NVIDIA\", \"Netflix\", \"ETHI\"]\n",
    "\n",
    "for _ in range(1000):\n",
    "    customer_id = 'CUST00' + str(random.randint(1, num_customers))\n",
    "    stock = random.choice(stocks)\n",
    "    quantity = random.randint(1, 100)\n",
    "    value_per_stock = round(random.uniform(50, 2000), 2)\n",
    "    current_value = round(quantity * value_per_stock, 2)\n",
    "    gain_loss_percentage = round(random.uniform(-20, 40), 2)\n",
    "    advisor_note = fake.sentence(nb_words=10)\n",
    "\n",
    "    portfolio.append({\n",
    "        \"customer_id\": customer_id,\n",
    "        \"stock_name\": stock,\n",
    "        \"quantity\": quantity,\n",
    "        \"current_value\": current_value,\n",
    "        \"gain_loss_percentage\": gain_loss_percentage\n",
    "    })\n",
    "\n",
    "#generate portfolio data\n",
    "portfolio_df = pd.DataFrame(portfolio)\n",
    "spark.createDataFrame(portfolio_df).write.mode(\"overwrite\").saveAsTable(portfolio_table)\n",
    "\n",
    "\n",
    "# --- 3. Generate Transactions Table ---\n",
    "transaction_ids = []\n",
    "transactions = []\n",
    "\n",
    "for i in range(1000):\n",
    "    transaction_id = f\"T00{i+1:04d}\"\n",
    "    transaction_ids.append(transaction_id)\n",
    "    customer_id = 'CUST00' + str(random.randint(1, num_customers))\n",
    "    amount = round(random.uniform(10, 5000), 2)\n",
    "    txn_date = datetime.now() - timedelta(days=random.randint(1, 365))\n",
    "    location = fake.city()\n",
    "\n",
    "    transactions.append({\n",
    "        \"transaction_id\": transaction_id,\n",
    "        \"customer_id\": customer_id,\n",
    "        \"amount\": amount,\n",
    "        \"date\": txn_date.strftime(\"%Y-%m-%d\"),\n",
    "        \"location\": location\n",
    "    })\n",
    "\n",
    "transactions_df = pd.DataFrame(transactions)\n",
    "spark.createDataFrame(transactions_df).write.mode(\"overwrite\").saveAsTable(transaction_table)\n",
    "\n",
    "\n",
    "# --- 4. Generate Fraud Alerts Table ---\n",
    "fraud_alerts = []\n",
    "fraud_sample = random.sample(transaction_ids, k=200)  # ~20% transactions flagged\n",
    "\n",
    "# Predefined realistic fraud alert descriptions\n",
    "alert_templates = [\n",
    "    \"Suspicious foreign ATM withdrawal\",\n",
    "    \"Multiple failed login attempts detected\",\n",
    "    \"Unusual high-value online purchase\",\n",
    "    \"Card skimming suspected at local store\",\n",
    "    \"IP address mismatch from different countries\",\n",
    "    \"Large fund transfer flagged without prior notice\",\n",
    "    \"Transaction outside of usual customer location\",\n",
    "    \"Rapid successive purchases over short period\",\n",
    "    \"Abnormal account access time\",\n",
    "    \"Attempted transaction blocked due to policy violation\"\n",
    "]\n",
    "\n",
    "# Predefined analyst notes\n",
    "analyst_note_templates = [\n",
    "    \"Escalate to fraud investigation team immediately.\",\n",
    "    \"Customer notification pending confirmation.\",\n",
    "    \"Freeze account temporarily pending investigation.\",\n",
    "    \"Monitor customer account for next 48 hours.\",\n",
    "    \"Review transaction logs for linked accounts.\",\n",
    "    \"Manual verification required before releasing funds.\",\n",
    "    \"Severity flagged based on historical fraud pattern.\",\n",
    "    \"Advise customer to reset credentials immediately.\",\n",
    "    \"Flagged under standard AML compliance rules.\",\n",
    "    \"Notify compliance team for further action.\"\n",
    "]\n",
    "\n",
    "for txn_id in fraud_sample:\n",
    "    severity = random.choices([\"Low\", \"Medium\", \"High\"], weights=[0.3, 0.4, 0.3])[0]\n",
    "    alert_description = random.choice(alert_templates)\n",
    "    analyst_notes = random.choice(analyst_note_templates)\n",
    "\n",
    "    fraud_alerts.append({\n",
    "        \"transaction_id\": txn_id,\n",
    "        \"alert_description\": alert_description,\n",
    "        \"severity_level\": severity,\n",
    "        \"analyst_notes\": analyst_notes\n",
    "    })\n",
    "\n",
    "fraud_df = pd.DataFrame(fraud_alerts)\n",
    "spark.createDataFrame(fraud_df).write.mode(\"overwrite\").saveAsTable(fraud_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca2b9beb-b29a-47fa-945e-8d8a2b903853",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(customers_df)\n",
    "display(portfolio_df)\n",
    "display(transactions_df)\n",
    "display(fraud_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01a-create-synthetic-data-structured",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
